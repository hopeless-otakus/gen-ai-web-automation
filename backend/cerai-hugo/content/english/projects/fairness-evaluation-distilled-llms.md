---

title: "Fairness evaluation of distilled LLMs"
image: "https://static.scientificamerican.com/sciam/cache/file/9645D223-B8AE-4CCA-A3E877074BED18B2_source.jpg?w=600"
draft: false
researchers: [Eshan Gujarati, Bavish Kulur, Karthick Seshadri]
filters: ["ai-and-society"]
tags: [ llm, ai-and-society, deployability]
reslinks: [https://arxiv.org/abs/2309.00770, https://arxiv.org/abs/2402.13116]
reslinktitles: ["Bias and Fairness in Large Language Models: A Survey", "A Survey on Knowledge Distillation of Large Language Models"]
---

Smaller, task-specific models can be created using knowledge distillation from large language models (LLMs). 

The goal of the project is to:


(1) Evaluate whether fairness is preserved during distillation of LLMs for different distillation techniques used in the literature.


(2) Explore ways in which fairness can be preserved during distillation.