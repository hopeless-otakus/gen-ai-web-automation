---
title: "Embedding Fairness through Model Editing"
image: "https://imageio.forbes.com/specials-images/imageserve/5e1f8038da6d38000629ac5f/0x0.jpg?format=jpg&crop=5993,3372,x0,y361,safe&height=900&width=1600&fit=bounds"
researchers: ["Ambreesh P (CeRAI)", "Arjun Bhagoji (U Chicago)"]
reslinks: ["https://proceedings.mlr.press/v97/bhagoji19a.html"]
tags: ["safe-ai", "ai-and-society"]
reslinktitles: ["Bhagoji, A.N., Chakraborty, S., Mittal, P. &amp; Calo, S.. (2019). Analyzing Federated Learning through an Adversarial Lens", "Proceedings of the 36th International Conference on Machine Learning", "Proceedings of Machine Learning Research"]
filters: [safe-ai, ai-and-society]
draft: false
---

This project aims to devise various methods to embed fairness through model editing. The first methodology involves using Model Poisoning in a federated learning setting to embed fairness. [Bhagoji et al 2019]. The second methodology involves using Causal Counterfactuals to edit representations.