---

title: "Grounding RAI principles: Case Studies"
image: "https://www.microsoft.com/en-us/research/uploads/prod/2018/03/4Bets_AI_Header_03_2018_1000x400.jpg"
draft: false
researchers: [Gokul S Krishnan, Sivaramakrishnan Guruvayur, Srinath K R]
filters: ["making-ai-understandable"]
tags: [ai-and-society, regulation, governance]
collaborators: ["images/open-loop.png"]
reslinks: ["https://openloop.org/"]
reslinktitles: ["Open Loop"]
---

<strong>Partner:</strong> 

Open Loop is a global program supported by Meta. They partner with governments, tech companies, academia and civil society to co-create and test new governance frameworks through policy prototyping programs, and to support the evaluation of existing legal frameworks through regulatory sandbox exercises.

<strong>Aim:</strong> Mapping of generic RAI principles into grounded policies, governance models and regulations for sector-specific deployment of AI.
 
When AI models are deployed in various domains, the policies and guidelines recommended for each domain will be different. They will also be multi-dimensional in accordance to the level and means of governance(top-down regulation, self-regulation, and co-regulation). Thus there is the requirement to learn, understand and accordingly map the use cases, performances and deployment of AI models/systems to these policies tailored to the sector. This is further illustrated in the following examples.

1. **Finance**

   a. AI-based credit assessment and Lending

   b. Determining Fraudulent practices in financial markets

   c. Banking customer services through chat-bots

2. **Healthcare**

   a. Disease diagnosis and decision making

   b. Medical chatbots and virtual nursing assistants

3. **Education: AI-based Learning Management systems**

   a. Equality of Assessment

   b. Educational material allocation

4. **Transportation**

   a. Autonomous cars and accidents

   b. Emergency transport allocation

   c. Equity in the transport sector

5. **Law enforcement**

   a. Criminal behavior and predictive policing

6. **HR**

   a. CV selection and Job advertisements

7. **Manufacturing**

   a. Defect detection and quality control

<strong>Output - Report 1 Chapters:</strong>

1. Survey of Open Source Explainability Toolkits for Fraud Detection in the Finance Sector (1.a)

2. Ensuring Ethical Implementation of Large Language Models in EdTech: Mitigating Cheating and Plagiarism Risks through Grounding and Responsible AI Practices (3.a)

3. Responsible AI + Human Collaboration in Social Media Moderation 

4. Evaluating Deployability of LLMs: Responsible AI of LLMs in Healthcare & Biomedical sector (2.a and 2.b)

5. Responsible AI in Applications of Recommender Systems (adapt for 6.a and 7.a)

6. Grounding Explainable AI Principles in Medical Imaging (2.a)

For each case/chapter, we elucidate the following dimensions:

| #   | Section                                                                                 |
| --- | --------------------------------------------------------------------------------------- |
| 1   | Application domain description                                                          |
| 2   | AI tech description review                                                              |
| 3   | Motivation of RAI in this case through survey of problems, controversies, media coverage, court cases, etc |
| 4   | Survey of state-of-the-art in RAI in this case in tech and governance                   |
| 5   | Recommendations in tech and governance   